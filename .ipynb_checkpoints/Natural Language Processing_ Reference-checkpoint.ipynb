{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f74e28c3",
   "metadata": {},
   "source": [
    "# 1. Handling text in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f10e973e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = \"Ethics are built right into the ideals and objectives of the United Nations \"\n",
    "len(text1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77becab7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'are',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'and',\n",
       " 'objectives',\n",
       " 'of',\n",
       " 'the',\n",
       " 'United',\n",
       " 'Nations',\n",
       " '']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = text1.split(' ')\n",
    "text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "783bf51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005f1928",
   "metadata": {},
   "source": [
    "## Find specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f3036b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'ideals',\n",
       " 'objectives',\n",
       " 'United',\n",
       " 'Nations']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# long words: Words that are more than 3 letters long\n",
    "[w for w in text2 if len(w) > 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84e52f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'United', 'Nations']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find capitalized words\n",
    "[w for w in text2 if w.istitle()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "793485fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ethics', 'ideals', 'objectives', 'Nations']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words that end with s\n",
    "[w for w in text2 if w.endswith('s')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4e8bf7",
   "metadata": {},
   "source": [
    "## Find unique words: using set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "449ae283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text3 = 'To be or not to be'\n",
    "text4 = text3.split()\n",
    "len(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1796335a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96420366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'To', 'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(text4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc25da03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set([w.lower() for w in text4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a1923ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'be', 'not', 'or', 'to'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([w.lower() for w in text4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db3cf99",
   "metadata": {},
   "source": [
    "## some word comparison functions\n",
    "\n",
    "* s.startwith(t)\n",
    "* s.endswith(t)\n",
    "* t in s\n",
    "* s.isupper(); s.lower(); s.istitle()\n",
    "* s.isalpha(); s.isdigit(); s.isalnum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195fad3f",
   "metadata": {},
   "source": [
    "## String Operations\n",
    "\n",
    "* s.lower(); s.supper(); s.titlecase()\n",
    "* s.split()\n",
    "* s.splitlines()\n",
    "* s.join(t)\n",
    "* s.strip(); s.rstrip()\n",
    "* s.find(t); s.rfind(t)\n",
    "* s.replace(u,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30228c3",
   "metadata": {},
   "source": [
    "## From words to characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0eed4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', 'agad', 'g', '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5 = \"ouagadougou\"\n",
    "text6 = text5.split('ou')\n",
    "text6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1091cd1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ouagadougou'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ou'.join(text6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6205b574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ouagadougou']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text5.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46829efc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "empty separator",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/pf/6m70llld5kz3jp5trc8kh13w0000gn/T/ipykernel_19414/3018022739.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtext5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# we cannot split based on empty separator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: empty separator"
     ]
    }
   ],
   "source": [
    "text5.split('') # we cannot split based on empty separator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bda09bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'g', 'a', 'd', 'o', 'u', 'g', 'o', 'u']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(text5) # this is the right way to split words into characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ded5354",
   "metadata": {},
   "source": [
    "## Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18f2f5fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '\\t',\n",
       " 'A',\n",
       " 'quick',\n",
       " 'brown',\n",
       " 'fox',\n",
       " 'jumped',\n",
       " 'over',\n",
       " 'the',\n",
       " 'lazy',\n",
       " 'dog.',\n",
       " '']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text8 = '  \t A quick brown fox jumped over the lazy dog. '\n",
    "text8.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17129bc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A', 'quick', 'brown', 'fox', 'jumped', 'over', 'the', 'lazy', 'dog.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9 = text8.strip() # strip all non-needed white spaces\n",
    "text9.split(' ') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438db49b",
   "metadata": {},
   "source": [
    "## Chaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ddb986a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A quick brown fox jumped over the lazy dog.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find and replace\n",
    "text9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ee1b5419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.find('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ac58d9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.rfind('o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "616e6e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A quick brOwn fOx jumped Over the lazy dOg.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text9.replace('o', 'O')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a4a2bb",
   "metadata": {},
   "source": [
    "## Reading files line by line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "930e7dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We first compare our approach against recent methods\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open('text1.txt', 'r')\n",
    "f.readline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6def99cb",
   "metadata": {},
   "source": [
    "## Read the full file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96f85dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.seek(0)\n",
    "text12 = f.read()\n",
    "len(text12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e28efaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We first compare our approach against recent methods',\n",
       " 'for unpaired image-to-image translation on paired datasets',\n",
       " 'where ground truth input-output pairs are available for evaluation.',\n",
       " 'We then study the importance of both the adversarial',\n",
       " 'loss and the cycle consistency loss and compare our full',\n",
       " 'method against several variants. Finally, we demonstrate',\n",
       " 'the generality of our algorithm on a wide range of applications',\n",
       " 'where paired data does not exist. For brevity, we refer',\n",
       " 'to our method as CycleGAN. The PyTorch and Torch code,',\n",
       " 'models, and full results can be found at our website.']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13 = text12.splitlines()\n",
    "text13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5fb96ac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67838c07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We first compare our approach against recent methods'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20d1fed",
   "metadata": {},
   "source": [
    "## File operations\n",
    "\n",
    "* f = open(filename, mode)\n",
    "* f.readline(); f.read(); f.read(n)\n",
    "* for line in f: doSomething(line)\n",
    "* f.seek(n)\n",
    "* f.write(message)\n",
    "* f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0dda7f",
   "metadata": {},
   "source": [
    "## Issues with reading text files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ff29271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We first compare our approach against recent methods\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove the last newline character\n",
    "f = open(\"text1.txt\", 'r')\n",
    "text14 = f.readline()\n",
    "text14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c2525e",
   "metadata": {},
   "source": [
    "## how do you remove the last newline character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7502a93c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We first compare our approach against recent methods'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text14.rstrip() # we strip white spaces from the right side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6fab20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We first compare our approach against recent methods'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text14.strip() # we strip the white spaces starting from the left side"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f98649f",
   "metadata": {},
   "source": [
    "# 2. Regular Expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87aae728",
   "metadata": {},
   "source": [
    "## Processing free-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29ea652f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['#regex', '#pandas', '#python']\n"
     ]
    }
   ],
   "source": [
    "# Find words with hashtags\n",
    "tweet = \"@nltk Text analysis is awesome! #regex #pandas #python\"\n",
    "print([word for word in tweet.split() if word.startswith('#')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "17831262",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find callouts\n",
    "[w for w in tweet if w.startswith('@')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f75bc",
   "metadata": {},
   "source": [
    "## Callouts are more than just tokens beginning with '@'\n",
    "@utoronto.ca @gmail.com \n",
    "\n",
    "Match something after '@'\n",
    "- Alphabets\n",
    "- Numbers\n",
    "- Specoal symbols like '_'\n",
    "\n",
    "@[A-Za-z0-9]+ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a85e18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"Ethics',\n",
       " 'are',\n",
       " 'built',\n",
       " 'right',\n",
       " 'into',\n",
       " 'the',\n",
       " 'ideals',\n",
       " 'and',\n",
       " 'objectives',\n",
       " 'of',\n",
       " 'the',\n",
       " 'united',\n",
       " 'Nations\"',\n",
       " '#UNSG',\n",
       " '@',\n",
       " 'NY',\n",
       " 'Society',\n",
       " 'for',\n",
       " 'Ethical',\n",
       " 'Culture',\n",
       " 'bit.ly/2guVelr',\n",
       " '@UN',\n",
       " '@UN_Women']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text10 = '\"Ethics are built right into the ideals and objectives of the united \\\n",
    "Nations\" #UNSG @ NY Society for Ethical Culture bit.ly/2guVelr @UN @UN_Women'\n",
    "text11 = text10.split()\n",
    "text11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b879caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@', '@UN', '@UN_Women']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[w for w in text11 if w.startswith('@')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cabacf",
   "metadata": {},
   "source": [
    "## Import regular expression first\n",
    "\n",
    "@[A-Za-z0-9]+ \n",
    "\n",
    "@: starts with @ \\\n",
    "[A-Za-z0-9]: followed by any alphabet(upper or lower case), digit, or undersocre \\\n",
    "+: repeats at least onece, but any number of times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cf1f3405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@UN', '@UN_Women']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "[w for w in text11 if re.search('@[A-Za-z0-9_]+', w)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7ec873",
   "metadata": {},
   "source": [
    "## Meta-characters: Character matches\n",
    "\n",
    ". : wildcard, matches a single character \\\n",
    "^ : start of a string [^abc] match none of abc\\\n",
    "$ : end of a string \\\n",
    "[]: matches one of the set of characters within [] \\\n",
    "[a-z] : matches one of the range of character a,b,...,z \\ \n",
    "[^abc] : matches a character that is not a,b,or,c \\\n",
    "a|b : matches either a or b, where a and b are strings \\\n",
    "() : Scoping for operators \\\n",
    "\\ : Escape character for sepcial characters(\\t, \\n, \\b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7752f658",
   "metadata": {},
   "source": [
    "## Meta-characters: Character symbols\n",
    "\\b : Matches word bounday \\\n",
    "\\d : Any digit, equivalent to [0-9] \\\n",
    "\\D : Any non-digit, equivalent to [^0-9] \\\n",
    "\\s : Any whitespace, equivalent to [ \\t\\n\\r\\f\\v] \\\n",
    "\\S : Any non-whitespace, equivalent to [^ \\t\\n\\r\\f\\v] \\\n",
    "\\w : Alphabumeric character, equivalent to [a-zA-Z0-9_] \\\n",
    "\\W : Non-alphanumeric, equivalent to [^a-zA-Z0-9_]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9653f1",
   "metadata": {},
   "source": [
    "## Meta-characters: Repetitions\n",
    "\n",
    "there is not quote, but in juputer notebook, have to add quote\\\n",
    "'*' : matches zero or more occurences \\ \n",
    "'+' : matches one or more occurences \\\n",
    "? : matches zero or one occurences \\\n",
    "{n} : exactly n repetitions, n >= 0 \\\n",
    "{n,} : at least n repetions \\\n",
    "{,n} : at most n repetions \\\n",
    "{m,n} : at least m and at most n repetions\\\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61aad20",
   "metadata": {},
   "source": [
    "## Find specific characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b95950ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['o', 'u', 'a', 'a', 'o', 'u', 'o', 'u']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text12 = \"ouagadougou\"\n",
    "re.findall(r'[aeiou]', text12) # find all characters that match at least one of the hcaracters in the brackets\n",
    "# find all: find and list all of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20e26e8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['g', 'd', 'g']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[^aeiou]', text12) # find all characters that match none of aeiou"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a02940e",
   "metadata": {},
   "source": [
    "## Case study: Regular expression for Dates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a052b75",
   "metadata": {},
   "source": [
    "## Date variations for 23rd December 2021\n",
    "23-12-2021 \\\n",
    "23/12/2021 \\\n",
    "23/12/21\\\n",
    "12/23/2021 \\ \n",
    "23 Dec 2021 \\\n",
    "23 December 2021 \\ \n",
    "Dec 23, 2021 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "5787138c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'23-12-2021\\n23/12/2021\\n23/12/21\\n12/23/2021\\n23 Dec 2021\\n23 December 2021\\n Dec 23, 2021\\n Mar-20-2009\\n Mar 20,2009\\n06 May 1972\\nJan 24 1986\\nFeb, 2021'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dateStr = '23-12-2021\\n23/12/2021\\n23/12/21\\n12/23/2021\\n23 Dec 2021\\n23 December 2021\\n Dec 23, 2021\\n Mar-20-2009\\n Mar 20,2009\\n06 May 1972\\nJan 24 1986\\nFeb, 2021'\n",
    "dateStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "e29710df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dec 2021', 'May 1972', 'Feb, 2021']"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[,.]? \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "142b82ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mar-20-2009']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(?:Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Oct|Nov|Dec)-\\d{2}-\\d{4}',dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "72a7ef24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Dec 2021',\n",
       " '23 December 2021',\n",
       " 'Dec 23, 2021',\n",
       " '06 May 1972',\n",
       " 'Jan 24 1986']"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2},? )?\\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7220e370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23-12-2021', '23/12/2021', '12/23/2021']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2}[/-]\\d{2}[/-]\\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbb6fb59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23-12-2021', '23/12/2021', '23/12/21', '12/23/2021']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2}[/-]\\d{2}[/-]\\d{2,4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f255d4ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23-12-2021', '23/12/2021', '23/12/21', '12/23/2021']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{1,2}[/-]\\d{1,2}[/-]\\d{2,4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77504139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dec']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2} (Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5458dbce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Dec 2021']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'\\d{2} (?:Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Oct|Nov|Dec) \\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "87c2c554",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['23 Dec 2021', '23 December 2021', 'Dec 23, 2021', '06 May 1972']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', dateStr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2583d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "54317243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24 Jan 2001']"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line s The patient is a 44 year old married Caucasian woman, unemployed Decorator, living with husband and caring for two young children, who is referred by Capitol Hill Hospital PCP, Dr. Heather Zubia, for urgent evaluation/treatment till first visit with Dr. Toney Winkler IN EIGHT WEEKS on 24 Jan 2001.\"\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "e1770d2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['06 May 1972']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line 06 May 1972 SOS-10 Total Score:\"\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "9e3d816d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['October. 11, 2013']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line none; but currently has appt with new HJH PCP Rachel Salas, MD on October. 11, 2013 Other Agency Involvement: No\"\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]*[.] (?:\\d{2}, )?\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "43d13b75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line .Came back to US on Jan 24 1986, saw Dr. Quackenbush at Beaufort Memorial Hospital.  Checked VPA level and found it to be therapeutic and confirmed BPAD dx.  Also, has a general physician exam and found to be in good general health, except for being slightly overwt.\"\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|May|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96248f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "805cb49a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6/1998']"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line 6/1998 Primary Care Doctor:\"\n",
    "re.findall(r'\\d{1,2}[/-]\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f92d9b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = \"new line 06 May 1972 SOS-10 Total Score:\"\n",
    "re.findall(r'(?:\\d{2} )?(?:Jan|Feb|Mar|Apr|Jun|Jul|Aug|Sep|Oct|Nov|Dec)[a-z]* (?:\\d{2}, )?\\d{4}', t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed06d835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d8af5ef",
   "metadata": {},
   "source": [
    "# 3. Working with Text Data in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "498f6ecb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Monday: The doctor's appointment is at 2:45pm.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tuesday: The dentist's appointment is at 11:30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Wedneday: At 7:00pm, there is a basktball game!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Thursday: Be back home by 11:15 pm at the latest.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Friday: Take the train at 08:10 am, arrive at ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0     Monday: The doctor's appointment is at 2:45pm.\n",
       "1  Tuesday: The dentist's appointment is at 11:30...\n",
       "2    Wedneday: At 7:00pm, there is a basktball game!\n",
       "3  Thursday: Be back home by 11:15 pm at the latest.\n",
       "4  Friday: Take the train at 08:10 am, arrive at ..."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "time_sentences = [\"Monday: The doctor's appointment is at 2:45pm.\",\n",
    "                 \"Tuesday: The dentist's appointment is at 11:30 am.\",\n",
    "                 \"Wedneday: At 7:00pm, there is a basktball game!\", \n",
    "                 \"Thursday: Be back home by 11:15 pm at the latest.\", \n",
    "                 \"Friday: Take the train at 08:10 am, arrive at 9:00 am.\"]\n",
    "df = pd.DataFrame(time_sentences, columns=['text'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d22ec64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    46\n",
       "1    50\n",
       "2    47\n",
       "3    49\n",
       "4    54\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9e79e11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     7\n",
       "1     8\n",
       "2     8\n",
       "3    10\n",
       "4    11\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3a9e06e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1     True\n",
       "2    False\n",
       "3    False\n",
       "4    False\n",
       "Name: text, dtype: bool"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.contains('appointment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0590d7b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    4\n",
       "2    3\n",
       "3    4\n",
       "4    7\n",
       "Name: text, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.count(r'\\d') #count the number of digits in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c7a6a037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              [(2, 45)]\n",
       "1             [(11, 30)]\n",
       "2              [(7, 00)]\n",
       "3             [(11, 15)]\n",
       "4    [(08, 10), (9, 00)]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.findall(r'(\\d?\\d):(\\d\\d)') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e0bf9821",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/6m70llld5kz3jp5trc8kh13w0000gn/T/ipykernel_19414/2023952851.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'].str.replace(r'\\w+day\\b', '???')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          ???: The doctor's appointment is at 2:45pm.\n",
       "1       ???: The dentist's appointment is at 11:30 am.\n",
       "2           ???: At 7:00pm, there is a basktball game!\n",
       "3         ???: Be back home by 11:15 pm at the latest.\n",
       "4    ???: Take the train at 08:10 am, arrive at 9:0...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.replace(r'\\w+day\\b', '???')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8f12709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/pf/6m70llld5kz3jp5trc8kh13w0000gn/T/ipykernel_19414/3576794422.py:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0          Mon: The doctor's appointment is at 2:45pm.\n",
       "1       Tue: The dentist's appointment is at 11:30 am.\n",
       "2           Wed: At 7:00pm, there is a basktball game!\n",
       "3         Thu: Be back home by 11:15 pm at the latest.\n",
       "4    Fri: Take the train at 08:10 am, arrive at 9:0...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.replace(r'(\\w+day\\b)', lambda x: x.groups()[0][:3])\n",
    "# This method returns a tuple containing all the subgroups of the match\n",
    "# groups[0] is the first subgroup of the regular expression match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a01c40ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0   1\n",
       "0   2  45\n",
       "1  11  30\n",
       "2   7  00\n",
       "3  11  15\n",
       "4  08  10"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extract(r'(\\d?\\d):(\\d\\d)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a6d1db7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>11:30 am</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>11:15 pm</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>08:10 am</td>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:00 am</td>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0   1   2   3\n",
       "  match                      \n",
       "0 0        2:45pm   2  45  pm\n",
       "1 0      11:30 am  11  30  am\n",
       "2 0        7:00pm   7  00  pm\n",
       "3 0      11:15 pm  11  15  pm\n",
       "4 0      08:10 am  08  10  am\n",
       "  1       9:00 am   9  00  am"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extractall(r'((\\d?\\d):(\\d\\d) ?([ap]m))')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7eae5186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>hour</th>\n",
       "      <th>minute</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "      <td>2:45pm</td>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>0</th>\n",
       "      <td>11:30 am</td>\n",
       "      <td>11</td>\n",
       "      <td>30</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <th>0</th>\n",
       "      <td>7:00pm</td>\n",
       "      <td>7</td>\n",
       "      <td>00</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>0</th>\n",
       "      <td>11:15 pm</td>\n",
       "      <td>11</td>\n",
       "      <td>15</td>\n",
       "      <td>pm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>0</th>\n",
       "      <td>08:10 am</td>\n",
       "      <td>08</td>\n",
       "      <td>10</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9:00 am</td>\n",
       "      <td>9</td>\n",
       "      <td>00</td>\n",
       "      <td>am</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             time hour minute period\n",
       "  match                             \n",
       "0 0        2:45pm    2     45     pm\n",
       "1 0      11:30 am   11     30     am\n",
       "2 0        7:00pm    7     00     pm\n",
       "3 0      11:15 pm   11     15     pm\n",
       "4 0      08:10 am   08     10     am\n",
       "  1       9:00 am    9     00     am"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.extractall(r'(?P<time>(?P<hour>\\d?\\d):(?P<minute>\\d\\d) ?(?P<period>[ap]m))')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397e36c6",
   "metadata": {},
   "source": [
    "## 4. Internationalization and issues with Non-ASCII Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a111433f",
   "metadata": {},
   "source": [
    "there are words that have similar prunication: \n",
    "resume (e is french) \\\n",
    "\n",
    "* international language: chinese vs India \\\n",
    "written scripts: different languages \\\n",
    "\n",
    "Other character encoding \\\n",
    "* IBM EBCDIC \\\n",
    "* Latin-I \\\n",
    "* JIS: Japanese Industrial Standards\n",
    "* CCCII: Chinese Character Code for Inforamtion Interchange\n",
    "* EUC: Extendede Unix Code\n",
    "* Numerous other national standards\n",
    "* Unicode and UTF-8\n",
    "\n",
    "Diversity in Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d4259",
   "metadata": {},
   "source": [
    "# 5. Steps for data cleaning\n",
    "\n",
    "1. Escaping HTML characters \\\n",
    "2. Decoding data \\\n",
    "3. Apostrophe lookup \\ \n",
    "4. Removal of stop_words \\\n",
    "5. removal of punctuations \\\n",
    "6. removal of expressions \\\n",
    "7. split attached words \\\n",
    "8. Slangs loopup \\\n",
    "9. Standardizing words \\\n",
    "10. Removal of URLs  \\\n",
    "\n",
    "\n",
    "* 1. Grammer checking 2. Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8ff4b4",
   "metadata": {},
   "source": [
    "## Escaping HTML characters: \n",
    "Data obtained from web usually contains a lot of htmel entities like &lt; &gt; &amp. It is necessary to get rid of these entities. \\\n",
    "One approach is to directly remove them by using regular expression. \\\n",
    "Another approach is to use approptiate packages or modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d5038529",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'â€œI luv my &lt;3 iphone &amp; youâ€™re awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com'"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tweet = \"â€œI luv my &lt;3 iphone &amp; youâ€™re awsm apple. DisplayIsAwesome, sooo happppppy ðŸ™‚ http://www.apple.com\"\n",
    "original_tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dc3909",
   "metadata": {},
   "source": [
    "## Decoding data\n",
    "\n",
    "UTF-8 encoding is widely accepted and is recoomended to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "94e4e1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xe2\\x80\\x9cI luv my &lt;3 iphone &amp; you\\xe2\\x80\\x99re awsm apple. DisplayIsAwesome, sooo happppppy \\xf0\\x9f\\x99\\x82 http://www.apple.com'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_tweet.encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "377b613e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'I luv my &lt;3 iphone &amp; youre awsm apple. DisplayIsAwesome, sooo happppppy  http://www.apple.com'"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet = original_tweet.encode().decode(\"utf8\").encode('ascii', 'ignore')\n",
    "tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94278984",
   "metadata": {},
   "source": [
    "## Apostrophe Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0c773690",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1107857201.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/pf/6m70llld5kz3jp5trc8kh13w0000gn/T/ipykernel_19414/1107857201.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    APPOSTOPHES = {\"'s\" : \" is\", \"'re\" : \" are\", ...} ## Need a huge dictionary\u001b[0m\n\u001b[0m                                                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "APPOSTOPHES = {\"'s\" : \" is\", \"'re\" : \" are\", ...} ## Need a huge dictionary\n",
    "#here is just an example of making up the dictionary : cover all the possible cases\n",
    "words = tweet.split()\n",
    "reformed = [APPOSTOPHES[word] if word in APPOSTOPHES else word for word in words]\n",
    "reformed = \" \".join(reformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eb0280ee",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is dirty TEXT: A phone number +001234561234, moNey 3.333, some date like 09.08.2016 and weird ÄŒÃ¡rÃ¡kterÅ¡.']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ['This is dirty TEXT: A phone number +001234561234, moNey 3.333, some date like 09.08.2016 and weird ÄŒÃ¡rÃ¡kterÅ¡.']\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "49a8dbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is dirty text a phone number money some date like and weird carakters\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_digit(word):\n",
    "    try:\n",
    "        int(word)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "cedilla2latin = [[u'Ã', u'A'], [u'Ã¡', u'a'], [u'ÄŒ', u'C'], [u'Ä', u'c'], [u'Å ', u'S'], [u'Å¡', u's']]\n",
    "tr = dict([(a[0], a[1]) for (a) in cedilla2latin])\n",
    "\n",
    "def transliterate(line):\n",
    "    new_line = \"\"\n",
    "    for letter in line:\n",
    "        if letter in tr:\n",
    "            new_line += tr[letter]\n",
    "        else:\n",
    "            new_line += letter\n",
    "    return new_line\n",
    "\n",
    "text = ['This is dirty TEXT: A phone number +001234561234, moNey 3.333, some date like 09.08.2016 and weird ÄŒÃ¡rÃ¡kterÅ¡.']\n",
    "\n",
    "for line in text:\n",
    "    # decode line to worrk with utf8 symbols\n",
    "    line = line.encode().decode('utf8')\n",
    "    line = line.replace('+', ' ').replace('.', ' ').replace(',', ' ').replace(':', ' ')\n",
    "    # remove digits with regex\n",
    "    line = re.sub(\"(^|\\W)\\d+($|\\W)\", \" \", line)\n",
    "    # OR remove digits with casting to int\n",
    "    new_line = []\n",
    "    for word in line.split():\n",
    "        if not is_digit(word):\n",
    "            new_line.append(word)\n",
    "    line = \" \".join(new_line)\n",
    "    # transliterate to Latin characters\n",
    "    line = transliterate(line)\n",
    "    line = line.lower()\n",
    "    print (line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "f735ff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Ã': 'A', 'Ã¡': 'a', 'ÄŒ': 'C', 'Ä': 'c', 'Å ': 'S', 'Å¡': 's'}"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cedilla2latin = [[u'Ã', u'A'], [u'Ã¡', u'a'], [u'ÄŒ', u'C'], [u'Ä', u'c'], [u'Å ', u'S'], [u'Å¡', u's']]\n",
    "tr = dict([(a[0], a[1]) for (a) in cedilla2latin])\n",
    "tr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba27f96",
   "metadata": {},
   "source": [
    "# 6. Basic Natural Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166d6ec3",
   "metadata": {},
   "source": [
    "1. What is Natural Language: Language used for everyday communication by human \n",
    "2. What is Natural Language Processing: \n",
    "    (1) Any Computation, manipluation of natural language\n",
    "    (2) Natrual languages evolve:\n",
    "        - new words get added (ex: selfie)\n",
    "        - old words lose popularity (ex: thou)\n",
    "        - manings of words change (ex: learn)\n",
    "        - language rules themselves may change (position of vers in sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15034721",
   "metadata": {},
   "source": [
    "## NLP Tasks: A Broad Spectrum\n",
    "* Counting words, conting frequency of words\n",
    "* Finding sentence boundaies\n",
    "* Part of speech tagging\n",
    "* Parsing the sentence structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab11114",
   "metadata": {},
   "source": [
    "## Basic BLP Tasks with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "06184377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "#nltk.download('gutenberg')\n",
    "#from nltk.book import *\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "8779e1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Introductory Examples for the NLTK Book ***\n",
      "Loading text1, ..., text9 and sent1, ..., sent9\n",
      "Type the name of the text or sentence to view it.\n",
      "Type: 'texts()' or 'sents()' to list the materials.\n",
      "text1: Moby Dick by Herman Melville 1851\n",
      "text2: Sense and Sensibility by Jane Austen 1811\n",
      "text3: The Book of Genesis\n",
      "text4: Inaugural Address Corpus\n",
      "text5: Chat Corpus\n",
      "text6: Monty Python and the Holy Grail\n",
      "text7: Wall Street Journal\n",
      "text8: Personals Corpus\n",
      "text9: The Man Who Was Thursday by G . K . Chesterton 1908\n"
     ]
    }
   ],
   "source": [
    "from nltk.book import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f762c1",
   "metadata": {},
   "source": [
    "# Counting vocabulary of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "bd1407fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Text: Wall Street Journal>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "9ea82881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " 'Vinken',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " ',',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.']"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "f04b4d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sent7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ef18e1b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100676"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "8e88e8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(text7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "178bd4ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['burdens',\n",
       " 'Francisco',\n",
       " 'experts',\n",
       " 'speculative',\n",
       " 'Hale',\n",
       " \"''\",\n",
       " '250',\n",
       " 'Hampshire',\n",
       " 'impart',\n",
       " 'emerges']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(text7))[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9706d8",
   "metadata": {},
   "source": [
    "# Frequency of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "7dbde99e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({',': 4885, 'the': 4045, '.': 3828, 'of': 2319, 'to': 2164, 'a': 1878, 'in': 1572, 'and': 1511, '*-1': 1123, '0': 1099, ...})"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = FreqDist(text7)\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "9f29d59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12408"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "4af02b35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre', 'Vinken', ',', '61', 'years', 'old', 'will', 'join', 'the', 'board']"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabl = dist.keys()\n",
    "list(vocabl)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "0276dddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist['four']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "7b7a4988",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['billion',\n",
       " 'company',\n",
       " 'president',\n",
       " 'because',\n",
       " 'market',\n",
       " 'million',\n",
       " 'shares',\n",
       " 'trading',\n",
       " 'program']"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqwords = [w for w in vocabl if len(w) > 5 and dist[w] > 100]\n",
    "freqwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539845b6",
   "metadata": {},
   "source": [
    "## Normalization and stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "d0a47e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'listed', 'lists', 'listing', 'listings']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# normalization \n",
    "# make all words into lowercase \n",
    "input1 = \"List listed lists listing listings\"\n",
    "words1 = input1.lower().split(' ')\n",
    "words1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "51ddd8d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list', 'list', 'list', 'list', 'list']"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# semming\n",
    "porter = nltk.PorterStemmer()\n",
    "[porter.stem(t) for t in words1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c845b1f",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "300f37a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'rights',\n",
       " 'of']"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "udhr[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "f68bd8fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['univers',\n",
       " 'declar',\n",
       " 'of',\n",
       " 'human',\n",
       " 'right',\n",
       " 'preambl',\n",
       " 'wherea',\n",
       " 'recognit',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inher',\n",
       " 'digniti',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalien',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[porter.stem(t) for t in udhr[:20]] # stemming : make all words lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b94fbb7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Universal',\n",
       " 'Declaration',\n",
       " 'of',\n",
       " 'Human',\n",
       " 'Rights',\n",
       " 'Preamble',\n",
       " 'Whereas',\n",
       " 'recognition',\n",
       " 'of',\n",
       " 'the',\n",
       " 'inherent',\n",
       " 'dignity',\n",
       " 'and',\n",
       " 'of',\n",
       " 'the',\n",
       " 'equal',\n",
       " 'and',\n",
       " 'inalienable',\n",
       " 'right',\n",
       " 'of']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "[WNlemma.lemmatize(t) for t in udhr[:20]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725b1609",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "eb857abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children', \"shouldn't\", 'drink', 'sugary', 'drink', 'before', 'bed']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text11 = \"Children shouldn't drink sugary drink before bed\"\n",
    "text11.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "e2f83908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Children', 'should', \"n't\", 'drink', 'sugary', 'drink', 'before', 'bed']"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f08ab382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenization of sentences\n",
    "text12 = \"This is the first sentence. A gallon of milk in the U.S. costs $2.99. Is this the third sentence? Yes, it is!\"\n",
    "sentences = nltk.sent_tokenize(text12)\n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "dd3413c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This is the first sentence.',\n",
       " 'A gallon of milk in the U.S. costs $2.99.',\n",
       " 'Is this the third sentence?',\n",
       " 'Yes, it is!']"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bd87e5",
   "metadata": {},
   "source": [
    "# 7.Advanced NLP Tasks with NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6faf2ee",
   "metadata": {},
   "source": [
    "## POS tagging\n",
    "\n",
    "Abbreviation\tMeaning\\\n",
    "CC\tcoordinating conjunction\\\n",
    "CD\tcardinal digit \\\n",
    "DT\tdeterminer \\\n",
    "EX\texistential there \\\n",
    "FW\tforeign word \\\n",
    "IN\tpreposition/subordinating conjunction \\\n",
    "JJ\tThis NLTK POS Tag is an adjective (large) \\\n",
    "JJR\tadjective, comparative (larger) \\\n",
    "JJS\tadjective, superlative (largest) \\\n",
    "LS\tlist market \\\n",
    "MD\tmodal (could, will) \\\n",
    "NN\tnoun, singular (cat, tree) \\\n",
    "NNS\tnoun plural (desks) \\\n",
    "NNP\tproper noun, singular (sarah) \\\n",
    "NNPS\tproper noun, plural (indians or americans) \\\n",
    "PDT\tpredeterminer (all, both, half) \\\n",
    "POS\tpossessive ending (parent\\ â€˜s) \\\n",
    "PRP\tpersonal pronoun (hers, herself, him, himself) \\\n",
    "PRP$\tpossessive pronoun (her, his, mine, my, our  ) \\\n",
    "RB\tadverb (occasionally, swiftly) \\\n",
    "RBR\tadverb, comparative (greater) \\\n",
    "RBS\tadverb, superlative (biggest) \\\n",
    "RP\tparticle (about) \\\n",
    "TO\tinfinite marker (to) \\\n",
    "UH\tinterjection (goodbye) \\\n",
    "VB\tverb (ask) \\\n",
    "VBG\tverb gerund (judging) \\\n",
    "VBD\tverb past tense (pleaded) \\\n",
    "VBN\tverb past participle (reunified) \\\n",
    "VBP\tverb, present tense not 3rd person singular(wrap) \\\n",
    "VBZ\tverb, present tense with 3rd person singular (bases) \\\n",
    "WDT\twh-determiner (that, what) \\\n",
    "WP\twh- pronoun (who) \\\n",
    "WRB\twh- adverb (how) \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "35f69e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset('MD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "d8980302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Children', 'NNP'),\n",
       " ('should', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('drink', 'VB'),\n",
       " ('sugary', 'JJ'),\n",
       " ('drink', 'NN'),\n",
       " ('before', 'IN'),\n",
       " ('bed', 'NN')]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text13 = nltk.word_tokenize(text11)\n",
    "nltk.pos_tag(text13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "88db9707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Visiting', 'VBG'),\n",
       " ('aunts', 'NNS'),\n",
       " ('can', 'MD'),\n",
       " ('be', 'VB'),\n",
       " ('a', 'DT'),\n",
       " ('nuisance', 'NN')]"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text14 = nltk.word_tokenize(\"Visiting aunts can be a nuisance\")\n",
    "nltk.pos_tag(text14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "9206b7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S (NP Alice) (VP (V loves) (NP Bob)))\n"
     ]
    }
   ],
   "source": [
    "# Parsing sentence structure\n",
    "text15 = nltk.word_tokenize(\"Alice loves Bob\")\n",
    "grammar = nltk.CFG.fromstring(\"\"\"\n",
    "S -> NP VP\n",
    "VP -> V NP\n",
    "NP -> 'Alice' | 'Bob'\n",
    "V -> 'loves'\n",
    "\"\"\")\n",
    "\n",
    "parser = nltk.ChartParser(grammar)\n",
    "trees = parser.parse_all(text15)\n",
    "for tree in trees: \n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "548e8ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Grammar with 13 productions>"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text16 = nltk.word_tokenize(\"I saw the man with a telescope\")\n",
    "grammar1 = nltk.data.load('mygrammar.cfg') # mygrammar.cfg is a file\n",
    "grammar1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "b0222396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (VP (V saw) (NP (Det the) (N man)))\n",
      "    (PP (P with) (NP (Det a) (N telescope)))))\n",
      "(S\n",
      "  (NP I)\n",
      "  (VP\n",
      "    (V saw)\n",
      "    (NP (Det the) (N man) (PP (P with) (NP (Det a) (N telescope))))))\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(grammar1)\n",
    "trees = parser.parse_all(text16)\n",
    "for tree in trees:\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cdb611",
   "metadata": {},
   "source": [
    "## POS tagging and parsing ambiguity\n",
    "\n",
    "when sentences can interpreated into two ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "7d88d3c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The', 'old', 'man', 'the', 'boat']"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text18 = nltk.word_tokenize(\"The old man the boat\")\n",
    "text18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "d9357cee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'), ('old', 'JJ'), ('man', 'NN'), ('the', 'DT'), ('boat', 'NN')]"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "d3757aa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Colorless', 'NNP'),\n",
       " ('green', 'JJ'),\n",
       " ('ideas', 'NNS'),\n",
       " ('sleep', 'VBP'),\n",
       " ('furiously', 'RB')]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text19 = nltk.word_tokenize(\"Colorless green ideas sleep furiously\")\n",
    "nltk.pos_tag(text19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23669655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709b9fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c0ca23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef554242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc68b1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ab54ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc5a891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50299a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d91988",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb19c12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f61485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
